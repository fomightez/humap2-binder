{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Technical) Jupyter Notebook Standardizing Identifier Order In Adjacent Columns in hu.MAP2-provided CSV\n",
    "\n",
    "This parallels [the notebook 'Jupyter Notebook Standardizing Identifier Order In Adjacent Columns in hu.MAP2-provided CSV'](https://nbviewer.org/github/fomightez/humap3-binder/blob/main/additional_nbs/standardizing_initial_data/Standardizing_identifier_order_in_humap3-provided_csv.ipynb) to investigate if author-provided hu.MAP 2.0 data displays the same issues and fix if it does.   \n",
    "This will set things up so it will be convenient to compare author-provided hu.MAP 2.0 data to author-provided hu.MAP 3.0 data.\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "**Details**, i.e., the long story:\n",
    "\n",
    "Authors provided a CSV about the hu.MAP 2.0 complex.  Does it have issues like hu.MAP 3.0 data? If so, address it like I did there.\n",
    "\n",
    "This will set things up so it will be convenient to compare author-provided hu.MAP 2.0 data to author-provided hu.MAP 3.0 data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the complexes with confidence scores\n",
    "\n",
    "Because the author-provided source didn't work for the hu.MAP 3.0 data, I expected `curl -OL \"http://humap2.proteincomplexes.org/static/downloads/humap2/humap2_complexes_20200809.txt\"` to work on my local machine, yet fail on MyBinder because the involved port may be blocked on MyBinder for getting it from the original resource. Because of that expectation, I made a copy at https://gist.githubusercontent.com/fomightez/af3edda957e4d71acbaa30192e74e9af/raw/108a8c3fb3374a74ef3ca5d772a9dfe96e996c93/humap2_complexes_20200809.txt where MyBinder would have access. However, the curl of the original source works!! \n",
    "(Keeping a note about my copy now but using original sourc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  500k  100  500k    0     0  1472k      0 --:--:-- --:--:-- --:--:-- 1475k\n"
     ]
    }
   ],
   "source": [
    "!curl -OL \"http://humap2.proteincomplexes.org/static/downloads/humap2/humap2_complexes_20200809.txt\"\n",
    "# If that fails, uncomment & try the next line which will be guaranteed to work with MyBinder:\n",
    "#!curl -OL https://gist.githubusercontent.com/fomightez/af3edda957e4d71acbaa30192e74e9af/raw/108a8c3fb3374a74ef3ca5d772a9dfe96e996c93/humap2_complexes_20200809.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Put the data on the complexes into Pandas dataframe\n",
    "\n",
    "(I'm using uv here just because I want to learn about it. I could have run the code in the script right in this notebook, and skipped the pickling and read pickle steps.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the script to use with `uv` to read in the raw data and make a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1007  100  1007    0     0   3882      0 --:--:-- --:--:-- --:--:--  3888\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://raw.githubusercontent.com/fomightez/structurework/refs/heads/master/humap3-utilities/complexes_rawCSV_to_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inline script metadata from `\u001b[36mcomplexes_rawCSV_to_df.py\u001b[39m`\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 199ms\u001b[0m\u001b[0m                              \u001b[0m         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HuMAP2_ID</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Uniprot_ACCs</th>\n",
       "      <th>genenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuMAP2_00000</td>\n",
       "      <td>3</td>\n",
       "      <td>Q9BQS8 O95900</td>\n",
       "      <td>FYCO1 TRUB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HuMAP2_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102</td>\n",
       "      <td>ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuMAP2_00002</td>\n",
       "      <td>5</td>\n",
       "      <td>Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...</td>\n",
       "      <td>RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HuMAP2_00003</td>\n",
       "      <td>5</td>\n",
       "      <td>Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...</td>\n",
       "      <td>VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuMAP2_00004</td>\n",
       "      <td>4</td>\n",
       "      <td>Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92</td>\n",
       "      <td>ZFAND2B KIF13B ASB7 OGN C8orf34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>HuMAP2_07014</td>\n",
       "      <td>4</td>\n",
       "      <td>Q9HC97 Q92871 Q6S8J3 P13727 P31152</td>\n",
       "      <td>GPR35 PMM1 POTEE PRG2 MAPK4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>HuMAP2_07015</td>\n",
       "      <td>4</td>\n",
       "      <td>Q9H5L6 Q8N5N7 Q96E29 O75127 Q9NPE2 Q96I51</td>\n",
       "      <td>THAP9 MRPL50 MTERF3 PTCD1 NGRN RCC1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6962</th>\n",
       "      <td>HuMAP2_07016</td>\n",
       "      <td>5</td>\n",
       "      <td>Q99697 Q8NE31 P17509 P31274 Q2T9J0 Q8TAC2 P529...</td>\n",
       "      <td>PITX2 FAM13C HOXB6 HOXC9 TYSND1 JOSD2 NKX2-5 D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>HuMAP2_07017</td>\n",
       "      <td>2</td>\n",
       "      <td>Q53GT1 Q96GP6 P49448</td>\n",
       "      <td>KLHL22 SCARF2 GLUD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>HuMAP2_07018</td>\n",
       "      <td>2</td>\n",
       "      <td>Q86US8 Q2NKX9 Q9Y223</td>\n",
       "      <td>SMG6 C2orf68 GNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HuMAP2_ID  Confidence  \\\n",
       "0     HuMAP2_00000           3   \n",
       "1     HuMAP2_00001           4   \n",
       "2     HuMAP2_00002           5   \n",
       "3     HuMAP2_00003           5   \n",
       "4     HuMAP2_00004           4   \n",
       "...            ...         ...   \n",
       "6960  HuMAP2_07014           4   \n",
       "6961  HuMAP2_07015           4   \n",
       "6962  HuMAP2_07016           5   \n",
       "6963  HuMAP2_07017           2   \n",
       "6964  HuMAP2_07018           2   \n",
       "\n",
       "                                           Uniprot_ACCs  \\\n",
       "0                                         Q9BQS8 O95900   \n",
       "1             P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102   \n",
       "2     Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...   \n",
       "3     Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...   \n",
       "4                    Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92   \n",
       "...                                                 ...   \n",
       "6960                 Q9HC97 Q92871 Q6S8J3 P13727 P31152   \n",
       "6961          Q9H5L6 Q8N5N7 Q96E29 O75127 Q9NPE2 Q96I51   \n",
       "6962  Q99697 Q8NE31 P17509 P31274 Q2T9J0 Q8TAC2 P529...   \n",
       "6963                               Q53GT1 Q96GP6 P49448   \n",
       "6964                               Q86US8 Q2NKX9 Q9Y223   \n",
       "\n",
       "                                              genenames  \n",
       "0                                           FYCO1 TRUB2  \n",
       "1               ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3  \n",
       "2     RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...  \n",
       "3     VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...  \n",
       "4                       ZFAND2B KIF13B ASB7 OGN C8orf34  \n",
       "...                                                 ...  \n",
       "6960                        GPR35 PMM1 POTEE PRG2 MAPK4  \n",
       "6961               THAP9 MRPL50 MTERF3 PTCD1 NGRN RCC1L  \n",
       "6962  PITX2 FAM13C HOXB6 HOXC9 TYSND1 JOSD2 NKX2-5 D...  \n",
       "6963                                KLHL22 SCARF2 GLUD2  \n",
       "6964                                   SMG6 C2orf68 GNE  \n",
       "\n",
       "[6965 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!uv run complexes_rawCSV_to_df.py humap2_complexes_20200809.txt\n",
    "import pandas as pd\n",
    "rd_df = pd.read_pickle('raw_complexes_pickled_df.pkl')\n",
    "rd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial idea to make in-order was to collect the identifiers in the Uniprot_ACCs & genenames columns by exploding the columns **together** and then making a list that is reduced to just the unique set. Then that would serve as a basis making a lookup table to relate the contents of the two columns.    \n",
    "But that doesn't work for both columns together as I had discovered, & cover next the reasoning, and so the code is left with what works and that is just 'exploding' one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can use Pandas `explode()`-related code I worked out in relation to using `rd_df` data already (see `notebooks/Working_with_hu.MAP3_data_with_Python_in_Jupyter_Basics.ipynb`)\n",
    "# to make the step of flattening the Uniprot_ACCs\n",
    "intermed_df = rd_df.copy()\n",
    "intermed_df['Uniprot_ACCs'] = intermed_df['Uniprot_ACCs'].str.split()\n",
    "#intermed_df['genenames'] = intermed_df['genenames'].str.split() # cannot use explode with both columns because out of 6965 rows, 204 rows don't have same number of indentifiers in the two columns (?!?! Do some identifiers occur twice in one or other?)\n",
    "# Now use explode to create a new row for each element in both columns\n",
    "expanded_df = intermed_df.explode(['Uniprot_ACCs']).copy()\n",
    "# Reset the index \n",
    "expanded_df = expanded_df.reset_index(drop=True)\n",
    "len(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't work as I had thought for both columns, read on for as to why and how fixed so ultimately exploding those two columns together will work (since the code I made made elsewhere and used was assuming 'exploding' the columns would work well)....\n",
    "\n",
    "#### Detour to see why mismatching number of identifiers in the two columns, `Uniprot_ACCs` & `genenames`, in 204 rows\n",
    "\n",
    "Noted something curious while drafting the code for the above cell..\n",
    "\n",
    "Found couldn't use `explode()` with both columns of the entire 'raw data' dataframe because out of 15326 rows, 279 rows (see next cell showing this) don't have same number of indentifiers in the two columns (?!?! Do some identifiers occur twice in one or other?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total rows in the CSV: <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">6965</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total rows in the CSV: \u001b[1;30m6965\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total Rows where the number of identifiers in the\n",
       "two adjacent columns aren't the same: <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">204</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total Rows where the number of identifiers in the\n",
       "two adjacent columns aren't the same: \u001b[1;30m204\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intermed_df = rd_df.copy()\n",
    "intermed_df['Uniprot_ACCs'] = intermed_df['Uniprot_ACCs'].str.split()\n",
    "intermed_df['genenames'] = intermed_df['genenames'].str.split()\n",
    "#intermed_df.head()\n",
    "num = 0\n",
    "for row in intermed_df.itertuples():\n",
    "    if len(row.Uniprot_ACCs) != len(row.genenames):\n",
    "        num+=1\n",
    "import rich\n",
    "rich.print(f\"Total rows in the CSV: [bold black]{len(intermed_df)}[/bold black]\")\n",
    "rich.print(f\"Total Rows where the number of identifiers in the\\ntwo adjacent columns aren't the same: [bold black]{num}[/bold black]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some examples that can be explored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HuMAP2_ID</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Uniprot_ACCs</th>\n",
       "      <th>genenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>HuMAP2_06542</td>\n",
       "      <td>5</td>\n",
       "      <td>[P52756, Q12872, Q96I25, O15042, Q8IWX8, P98175]</td>\n",
       "      <td>[RBM5, SFSWAP, ZRSR2P1, RBM17, U2SURP, CHERP, RBM10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>HuMAP2_06409</td>\n",
       "      <td>5</td>\n",
       "      <td>[Q14954, P43631, Q14953, Q8TAX7]</td>\n",
       "      <td>[KIR2DS1, KIR2DS2, KIR2DS5, KIR3DP1, MUC7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>HuMAP2_04110</td>\n",
       "      <td>5</td>\n",
       "      <td>[Q9Y620, Q96EW2, P43355, Q8IWZ3, Q07617, O15480, O15481, Q8N7X4, Q96A19]</td>\n",
       "      <td>[RAD54B, HSPBAP1, MAGEA1, ANKHD1, SPAG1, MAGEB3, FBXL18, MAGEB4, MAGEB6, CCDC102A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>HuMAP2_05705</td>\n",
       "      <td>1</td>\n",
       "      <td>[Q8N6C8]</td>\n",
       "      <td>[LILRA3, LILRB2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>HuMAP2_05424</td>\n",
       "      <td>5</td>\n",
       "      <td>[Q86TB9, Q6PJG9]</td>\n",
       "      <td>[PATL1, LRFN4, IGHM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>HuMAP2_02536</td>\n",
       "      <td>2</td>\n",
       "      <td>[P01023]</td>\n",
       "      <td>[A2M, PZP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>HuMAP2_05931</td>\n",
       "      <td>4</td>\n",
       "      <td>[Q00978, Q9BU19, P42224, P52630]</td>\n",
       "      <td>[RPS26P11, IRF9, ZNF692, STAT1, STAT2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>HuMAP2_05255</td>\n",
       "      <td>3</td>\n",
       "      <td>[Q8N6C8, Q8NHL6]</td>\n",
       "      <td>[LILRA3, LILRB2, LILRB1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HuMAP2_00932</td>\n",
       "      <td>5</td>\n",
       "      <td>[P22392, O00746, Q13232, P22392, Q9H4I3]</td>\n",
       "      <td>[NME2P1, NME2, NME4, NME3, NME2, TRABD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>HuMAP2_02538</td>\n",
       "      <td>4</td>\n",
       "      <td>[Q86UD1, Q15545]</td>\n",
       "      <td>[OAF, TAF7, TRAC]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HuMAP2_ID  Confidence  \\\n",
       "6492  HuMAP2_06542           5   \n",
       "6360  HuMAP2_06409           5   \n",
       "4077  HuMAP2_04110           5   \n",
       "5662  HuMAP2_05705           1   \n",
       "5385  HuMAP2_05424           5   \n",
       "2516  HuMAP2_02536           2   \n",
       "5885  HuMAP2_05931           4   \n",
       "5216  HuMAP2_05255           3   \n",
       "928   HuMAP2_00932           5   \n",
       "2518  HuMAP2_02538           4   \n",
       "\n",
       "                                                                  Uniprot_ACCs  \\\n",
       "6492                          [P52756, Q12872, Q96I25, O15042, Q8IWX8, P98175]   \n",
       "6360                                          [Q14954, P43631, Q14953, Q8TAX7]   \n",
       "4077  [Q9Y620, Q96EW2, P43355, Q8IWZ3, Q07617, O15480, O15481, Q8N7X4, Q96A19]   \n",
       "5662                                                                  [Q8N6C8]   \n",
       "5385                                                          [Q86TB9, Q6PJG9]   \n",
       "2516                                                                  [P01023]   \n",
       "5885                                          [Q00978, Q9BU19, P42224, P52630]   \n",
       "5216                                                          [Q8N6C8, Q8NHL6]   \n",
       "928                                   [P22392, O00746, Q13232, P22392, Q9H4I3]   \n",
       "2518                                                          [Q86UD1, Q15545]   \n",
       "\n",
       "                                                                               genenames  \n",
       "6492                                [RBM5, SFSWAP, ZRSR2P1, RBM17, U2SURP, CHERP, RBM10]  \n",
       "6360                                          [KIR2DS1, KIR2DS2, KIR2DS5, KIR3DP1, MUC7]  \n",
       "4077  [RAD54B, HSPBAP1, MAGEA1, ANKHD1, SPAG1, MAGEB3, FBXL18, MAGEB4, MAGEB6, CCDC102A]  \n",
       "5662                                                                    [LILRA3, LILRB2]  \n",
       "5385                                                                [PATL1, LRFN4, IGHM]  \n",
       "2516                                                                          [A2M, PZP]  \n",
       "5885                                              [RPS26P11, IRF9, ZNF692, STAT1, STAT2]  \n",
       "5216                                                            [LILRA3, LILRB2, LILRB1]  \n",
       "928                                              [NME2P1, NME2, NME4, NME3, NME2, TRABD]  \n",
       "2518                                                                   [OAF, TAF7, TRAC]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter rows where list lengths differ\n",
    "i_df = rd_df.copy()\n",
    "i_df['Uniprot_ACCs'] = i_df['Uniprot_ACCs'].str.split()\n",
    "i_df['genenames'] = i_df['genenames'].str.split()\n",
    "mismtchd = i_df[i_df['Uniprot_ACCs'].apply(len) != i_df['genenames'].apply(len)]\n",
    "\n",
    "# Randomly select 10 rows from the filtered DataFrame\n",
    "sample_rows = mismtchd.sample(n=10, random_state=3) #use state to assure sampling is same when re-run\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(sample_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice sampling of examples to examine.\n",
    "\n",
    "I can clearly see several don't have equal numbers in each column.\n",
    "- Example from row #2516 `[P01023]\t[A2M, PZP]`. Second column has two genenames, while first has one identifier.\n",
    "- Example from row #5216: `[Q8N6C8, Q8NHL6]\t[LILRA3, LILRB2, LILRB1]`. Two identifiers in first columns and three in second.\n",
    "- Example from row #928: `[P22392, O00746, Q13232, P22392, Q9H4I3]\t[NME2P1, NME2, NME4, NME3, NME2, TRABD]` Five identifiers in first column and six in second column.\n",
    "  \n",
    "In [the notebook 'Jupyter Notebook Standardizing Identifier Order In Adjacent Columns in hu.MAP2-provided CSV'](https://nbviewer.org/github/fomightez/humap3-binder/blob/main/additional_nbs/standardizing_initial_data/Standardizing_identifier_order_in_humap3-provided_csv.ipynb) I had worked through similar examples in greater detail to gain insight into what was going on, and at the same time, start to understand maybe how to address the issues.  \n",
    "**Here though**, I am going to proceed for now and assume the issues are similar to seen and addressed there, or at least I covered most of the possibilities, since this is a smaller subset and the same authors processed the data it seems.  \n",
    "**UPDATE**: later, mostly around the time I had generated a preliminary output I called `DRAFThumap2_complexes_20200809InOrderMatched.csv` by **initially**(pretty much[I had iterated adding some hu.MAP 2.0-specific handling a bit before saving that]) running the hu.MAP 3.0-handling code on the hu.MAP 2.0, I found beyond the possibilities already covered in hu.MAP 3.0, examples involving synonyms use and where authors used gene names no longer represented in UniProt and had to add special handling for those identifiers in accounting for things to set up for keeping balanced & checking for balance in the two columns. Plus, the handling for those with multiple names seems different in the hu.MAP 2.0 vs. hu.MAP 3.0 data. (Inconsistent handling scheme highlights that without this standardization it would be hard to compare the hu.MAP 2.0 vs. hu.MAP 3.0 data, which I am still trying to find if they did. I can see mention of increases but about cases where they lost members of complexes?)\n",
    "\n",
    "Here are some examples of the types of things I mention in the update:  \n",
    "Then further looking into those cases found things like following in author-provided `humap2_complexes_20200809.txt`:\n",
    "```text\n",
    "HuMAP2_06154,4,  Q86YV6 Q9H7B4   Q9H9G7,HSP90AA5P HSP90AB2P MYLK4 SMYD3 HSP90AB3P HSP90AB4P AGO3\n",
    "```\n",
    "\n",
    "`HSP90AB4P` corresponds to UniProt accension `Q58FF6`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AB2P` corresponds to UniProt accension `Q58FF8`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AB3P` corresponds to UniProt accension `Q58FF7`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AA5P` corresponds to UniProt accension `Q58FG0`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "Why so unbalanced?\n",
    "\n",
    "```text\n",
    "HuMAP2_00547,5, P58876 P16104 P23527 Q96T23 Q6ZRQ5 Q8IUE6,H3-2 HIST1H2BD H2AFX HIST1H2BO RSF1 MMS22L HIST2H2AB\n",
    "```\n",
    "\n",
    "I can account for all six identifiers in the `Uniprot_ACCs` column, as long as I add in using synonymys, but there is no corresponding identifier for `H3-2` that seems to correspond to `Q5TEC6`, if I had to guess. Why unbalanced?\n",
    "\n",
    "```text\n",
    "HuMAP2_01550,4,Q8NB90  Q9BW66 Q9BVQ7 Q9NX04,SPATA5 RIPK4 CINP SPATA5L1 C1orf109\n",
    "```\n",
    "\n",
    "Note the extended gap between: `Q8NB90  Q9BW66`. What is that about and why unbalanced number of items?    \n",
    "When I look, I see `Q8NB90` corresponds to `AFG2A` and a synonym is `SPATA5`. So that is accounted for.  \n",
    "Note the gap would be here and that above and below account for the ones flanking `RIPK4`.\n",
    "When I look, I see `Q9BW66` correspnds to `CINP`. So that is accounted for.  \n",
    "When I look, I see `Q9BVQ7` corresponds  to `AFG2B` and a synonym is `SPATA5L1`. So that is accounted for.  \n",
    "When I look, I see `Q9NX04` corresponds to `AIRIM` and a synonym is `\n",
    "C1orf109`. So that is accounted for.  \n",
    "Turns out as the gap hinted, `RIPK4` seems to be the one missing a corresponding entry in the `Uniprot_ACCs` column. It seems it should be `P57078`.\n",
    "\n",
    "```text\n",
    "HuMAP2_00006,4,P07199 Q96C28 O43296  Q5CZA5,CENPB ZNF707 ZNF264 ZNF678 ZNF805\n",
    "```\n",
    "Four on one side and five on the other. ZNF678 probably corresponds to Q5SXM1.  \n",
    "Note the extended gap between: `O43296  Q5CZA5`. What is that about and why unbalanced number of items?  \n",
    "`P07199` corresponds to `CENPB`.  \n",
    "`Q96C28` corresponds to `ZNF707`.  \n",
    "`O43296` corresponds to `ZNF264`.\n",
    "Note the gap would be here and that above and below account for the ones flanking `ZNF678`.  \n",
    "`Q5CZA5` corresponds to `ZNF805`.\n",
    "Turns out as the gap hinted, `ZNF678` seems to be the one missing a corresponding entry in the `Uniprot_ACCs` column. It seems it should be `Q5SXM1`.\n",
    "\n",
    "\n",
    "```text\n",
    "HuMAP2_00011,5, O00339 Q99435 Q9BXX0 Q92832 Q3ZCT1,C4orf48 MATN2 NELL2 EMILIN2 NELL1 ZNF260\n",
    "```\n",
    "\n",
    "Based on seeing a gap there and `C4orf48` coinciding and columns not balancing, I'm guessing `C4orf48` should have a matching entry of `Q5BLP8`.  \n",
    "\n",
    "```text\n",
    "HuMAP2_03893,2,Q9H8T0 Q96ED9 Q05DH4 Q86VS8 Q8N612 Q9UJC3,AKTIP HOOK2 FAM160A1 HOOK3 FAM160A2 HOOK1\n",
    "```\n",
    "\n",
    "```text\n",
    "HuMAP2_04870,5,P04439 ,HLA-A LOC100507703\n",
    "```\n",
    "\n",
    "One in one column and two in the other? There seems to be a gap there after `P04439`: `P04439 ,`?\n",
    "\n",
    "```text\n",
    "HuMAP2_04875,4,Q5JXC2  P09917,MIIP RUNDC1 ALOX5\n",
    "```\n",
    "\n",
    "Two in one column and three in the other?  There seems to be a gap there between `Q5JXC2` & `P09917`: `Q5JXC2  P09917,`?\n",
    "\n",
    "```text\n",
    "HuMAP2_06623,4, P30511 Q9NPC4 Q8NDV1 O15466,KLRA1P HLA-F A4GALT ST6GALNAC3 ST8SIA5\n",
    "```\n",
    "\n",
    "Four in one column and five in the other?  There seems to be a gap there before `P30511`?\n",
    "\n",
    "```text\n",
    "HuMAP2_04079,5,O75069 P62805  Q8WUP2 P68431 Q8N806 P68431 Q13111,TMCC2 H4C1 H3-2 FBLIM1 H3C1 UBR7 H3C1 CHAF1A\n",
    "```\n",
    "\n",
    "`P68431` occurs twice?\n",
    "\n",
    "For `P68431` just use single genename, unlike complex one involving semi-colons in hu.MAP 3.0 data, and so in the code below I had to adjust the special handling to do the accounting correctly to not add additional identifiers n the `Uniprot_ACCs` column when trying to balance.  \n",
    "\n",
    "```text\n",
    "HuMAP2_04092,4,Q8WXA9 O95232 P0DN76 Q13523 Q05519 Q8IZL8 Q99590 Q14498 Q7L014 P26368 P0DN76,SREK1 LUC7L3 U2AF1L5 PRPF4B SRSF11 PELP1 SCAF11 RBM39 DDX46 U2AF2 U2AF1L5\n",
    "HuMAP2_04092,4,Q8WXA9 O95232 P0DN76 Q13523 Q05519 Q8IZL8 Q99590 Q14498 Q7L014 P26368 P0DN76,SREK1 LUC7L3 U2AF1L5 PRPF4B SRSF11 PELP1 SCAF11 RBM39 DDX46 U2AF2 U2AF1L5\n",
    "```\n",
    "`P0DN76` occurs twice?\n",
    "\n",
    "```text\n",
    "HuMAP2_02212,2,P59665 P59665,DEFA1 DEFA1\n",
    "```\n",
    "\n",
    "`P59665` occurs twice and that is the only protein in this 'complex'?\n",
    "\n",
    "```text\n",
    "HuMAP2_01368,5,Q9Y3F4 P08621 O75534 Q9P2G9 Q7Z422 Q9H840 Q9BRS8 O14893 Q9H9B4 Q9NWZ8 O43353 Q8WXD5 P57678 Q16637 Q16637 Q9H3H3 Q9UHI6 Q9P2E3 P83369 Q8TEQ6,STRAP SNRNP70 CSDE1 KLHL8 SZRD1 GEMIN7 LARP6 GEMIN2 SFXN1 GEMIN8 RIPK2 GEMIN6 GEMIN4 SMN1 SMN1 C11orf68 DDX20 ZNFX1 LSM11 GEMIN5\n",
    "```\n",
    "\n",
    "`SMN1` occurs twice?\n",
    "\n",
    "I would imagine these duplicates, if plentiful, could throw off comparison of hu.MAP 2.0 vs hu.MAP 3.0 data especially if use count of associated complex members anywhere in assessment. And so I checked how many, see `Check_for_duplicates_in_author_provided_hu.MAP2.0_csv.ipynb`, and I'll be sure to fix on the standardized version so won't be an issue in downstream efforts. (Or maybe already fixed by way I do things?) \n",
    "\n",
    "**END OF UPDATE WHERE I HAD ORIGINALLY PROCEEDED AND FOUND LOTS OF ADDITIONAL HANDLING NEEDED AND INCONSISTENCIES WITH HOW HANDLED IN hu.MAP 3.0 data and came back to this point in notebook and noted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make lookup table for relating identifiers in the two columns, column Uniprot_ACCs and column genenames\n",
    "\n",
    "I already made a large lookup table for relating identifiers in the effort for [the notebook 'Jupyter Notebook Standardizing Identifier Order In Adjacent Columns in hu.MAP2-provided CSV'](https://nbviewer.org/github/fomightez/humap3-binder/blob/main/additional_nbs/standardizing_initial_data/Standardizing_identifier_order_in_humap3-provided_csv.ipynb).   \n",
    "Here there are only 6965 rows vs. the 15326 there. Plus, there's only 30573 identifiers in the '`Uniprot_ACCs`' column while there was 75531 there. So most of the identifiers probably handled in this lookup table.\n",
    "\n",
    "There I used the identifiers in the the '`Uniprot_ACCs`' column to look them up the UniProt Knowledgebase using the package Unipressed (see my [Unipressed-binder repo](https://github.com/fomightez/Unipressed-binder) for more on working with this package).  \n",
    "So I can take what I generated from there and see if it already covers what I need and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9963"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first make a list of all the identifiers in the 'Uniprot_ACCs' column\n",
    "ids_in_Uniprot_ACCs = list(set(expanded_df['Uniprot_ACCs'].to_list())) # the set will limit to unique set, eliminating ones that appear more than once\n",
    "len(ids_in_Uniprot_ACCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 9963 unique identifiers among all the identifiers in the 'Uniprot_ACCs' column in this hu.MAP 2.0 data. There's 13769 unique identifiers among all the identifiers in the 'Uniprot_ACCs' column in the hu.MAP 3.0 data.\n",
    "I can read what I had from there in here and then see what isn't covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  233k  100  233k    0     0   589k      0 --:--:-- --:--:-- --:--:--  589k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13769"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu_file_needed = \"look_up_dict_all_13769_Uniprot_ACCs.pkl\"\n",
    "import os\n",
    "if not os.path.isfile(lu_file_needed):\n",
    "    !curl -OL \"https://github.com/fomightez/humap3-binder/raw/refs/heads/main/additional_nbs/standardizing_initial_data/{lu_file_needed}\"\n",
    "import time\n",
    "time.sleep(1.0)\n",
    "import pickle\n",
    "with open(\"look_up_dict_all_13769_Uniprot_ACCs.pkl\", \"rb\") as f:\n",
    "        h3_lookup_dict = pickle.load(f)\n",
    "len(list(h3_lookup_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the 13769 identifiers in the hu.MAP 3.0 data read in, I can see if there are any in the hu.MAP 2.0 data not already there by running set analysis on the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's 419 identifiers in h2 are not present in h3.\n"
     ]
    }
   ],
   "source": [
    "h2 = set(ids_in_Uniprot_ACCs)\n",
    "h3 = set(h3_lookup_dict.keys())\n",
    "missing_in_h3 = h2 - h3\n",
    "if missing_in_h3:\n",
    "  print(f\"There's {len(missing_in_h3)} identifiers in h2 are not present in h3.\")\n",
    "else:\n",
    "  print(\"All items in h2 are present in h3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 419 is not insignificant, as it is way more than I'd want to handle by hand, it won't take a long time to look those up compared to the hours it took to collect all the matching gene names for the 13769.\n",
    "So here I want to expand on the lookup table stored in `\"look_up_dict_all_13769_Uniprot_ACCs.pkl\"` and use that expanded lookup table for the effort here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "# This first cell sets things up for querying UniProt; THIS COMES FROM https://nbviewer.org/github/fomightez/humap3-binder/blob/main/additional_nbs/standardizing_initial_data/Standardizing_identifier_order_in_humap3-provided_csv.ipynb\n",
    "from unipressed import UniprotkbClient\n",
    "import time\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def process_uniprot_chunk(id_list):\n",
    "    \"\"\"\n",
    "    Process a chunk of UniProt IDs and return a dictionary of ID to gene name mappings.\n",
    "    \"\"\"\n",
    "    chunk_dict = {}\n",
    "    for uniprot_id in id_list:\n",
    "        try:\n",
    "            uniprot_record = UniprotkbClient.fetch_one(uniprot_id)\n",
    "            #lookup_dict[uniprot_id] = uniprot_record['genes'][0]['geneName']['value'] #worked for when one 'gene' in the list returned by `uniprot_record['genes']`\n",
    "            # HOWEVER...\n",
    "            # some IDs like `Q96LI6` and `Q9BQ83` give more than one gene for `uniprot_record['genes']` and the CSV from the hu.MAP3 people was combining \n",
    "            # those to things like `HSFY1; HSFY2` and `SLX1A; SLX1B`, respectively. To do accurate accounting and keep close to that (or at least keep the option to keep close to that), I want to recapitulate that, too.\n",
    "            if 'genes' in uniprot_record:\n",
    "                chunk_dict[uniprot_id] = '; '.join([x['geneName']['value'] for x in uniprot_record['genes']])\n",
    "            else:\n",
    "                if uniprot_id == 'B3KT37': # special case I looked into\n",
    "                    chunk_dict[uniprot_id] = 'SPECIALin_UniProt_and_VETELKLIC_part_similar_to_YWHAE_but_no_official_gene'\n",
    "                else:\n",
    "                    chunk_dict[uniprot_id] = 'SPECIALin_UniProt_but_no_gene'\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 400:\n",
    "                chunk_dict[uniprot_id] = 'not_known'\n",
    "                print(f\"UniProt ID '{uniprot_id}' not found. Marked as 'not_known' in lookup_dict.\\n(Although for known case, '645345', this will be fixed later.)\")\n",
    "            else:\n",
    "                raise e\n",
    "        time.sleep(1.12)\n",
    "    return chunk_dict\n",
    "\n",
    "def process_all_ids_in_chunks(id_list, chunk_size=1000, output_dir='chunk_pickles', resume=True):\n",
    "    \"\"\"\n",
    "    Process all IDs in chunks and save each chunk as a pickle file.\n",
    "    Supports resuming from the last completed chunk.\n",
    "    \n",
    "    Args:\n",
    "        id_list (list): List of all UniProt IDs to process\n",
    "        chunk_size (int): Size of each chunk\n",
    "        output_dir (str): Directory to save pickle files\n",
    "        resume (bool): If True, skip already processed chunks\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    total_chunks = (len(id_list) + chunk_size - 1) // chunk_size\n",
    "    \n",
    "    # Find the last completed chunk if resuming\n",
    "    existing_chunks = []\n",
    "    if resume:\n",
    "        existing_chunks = [f for f in os.listdir(output_dir) if f.startswith('chunk_') and f.endswith('.pkl')]\n",
    "        existing_chunks.sort()  # Sort to find the highest number\n",
    "    \n",
    "    # Determine starting chunk\n",
    "    start_chunk = 0\n",
    "    if existing_chunks:\n",
    "        last_chunk = existing_chunks[-1]\n",
    "        start_chunk = int(last_chunk.split('_')[1].split('.')[0])  # Extract number from 'chunk_003.pickle'\n",
    "        print(f\"Resuming from chunk {start_chunk + 1}\")\n",
    "    \n",
    "    # Process remaining chunks\n",
    "    for i in range(start_chunk * chunk_size, len(id_list), chunk_size):\n",
    "        chunk_num = i // chunk_size + 1\n",
    "        chunk = id_list[i:i + chunk_size]\n",
    "        \n",
    "        pickle_filename = os.path.join(output_dir, f'chunk_{chunk_num:03d}.pkl')\n",
    "        \n",
    "        # Skip if chunk already exists and we're resuming\n",
    "        if resume and os.path.exists(pickle_filename):\n",
    "            print(f\"Skipping existing chunk {chunk_num}/{total_chunks}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing chunk {chunk_num}/{total_chunks} ({len(chunk)} IDs)\")\n",
    "        chunk_result = process_uniprot_chunk(chunk)\n",
    "        \n",
    "        with open(pickle_filename, 'wb') as f:\n",
    "            pickle.dump(chunk_result, f)\n",
    "        \n",
    "        print(f\"Saved {len(chunk_result)} entries to {pickle_filename}\")\n",
    "\n",
    "def combine_pickle_chunks(pickle_dir='chunk_pickles'):\n",
    "    \"\"\"\n",
    "    Combine all pickle files in the directory into a single dictionary.\n",
    "    \n",
    "    Args:\n",
    "        pickle_dir (str): Directory containing the pickle files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Combined dictionary of all chunks\n",
    "    \"\"\"\n",
    "    combined_dict = {}\n",
    "    pickle_files = sorted([f for f in os.listdir(pickle_dir) if f.endswith('.pkl')])\n",
    "    \n",
    "    for pickle_file in pickle_files:\n",
    "        with open(os.path.join(pickle_dir, pickle_file), 'rb') as f:\n",
    "            chunk_dict = pickle.load(f)\n",
    "            combined_dict.update(chunk_dict)\n",
    "        print(f\"Loaded {pickle_file}, combined dictionary now has {len(combined_dict)} entries\")\n",
    "    \n",
    "    return combined_dict\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "process_all_ids_in_chunks(list(missing_in_h3), chunk_size=500)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I looked into it some, I cannot tell where `missing_in_h3` is introducing `nan` that isn't even a string?!??! I don't think it will cause much issue so letting it be there for now and moving on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chunk_001.pkl, combined dictionary now has 419 entries\n"
     ]
    }
   ],
   "source": [
    "'''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "missing_lookup_dict = combine_pickle_chunks()\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to add that `missing_lookup_dict` to `h3_lookup_dict`. The next cell should do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "merged_lookup_dict = h3_lookup_dict.copy()\n",
    "merged_lookup_dict.update(missing_lookup_dict)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14188"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "len(list(merged_lookup_dict.keys()))\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it doesn't take up too much space (list 242K), store the lookup table in pickled form for having in case need for reference later. Or for re-running downstream steps without needing to make the lookup table again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ONLY RUN THIS WHEN NEED TO COLLECT LOOKUP INFORMATION!!!\n",
    "import pickle\n",
    "with open(\"look_up_dict_for_h2nh3_all_14188_Uniprot_ACCs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(merged_lookup_dict, f)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it didn't take up too much space, I stored the lookup table in pickled form for having in case need for reference later. Or fo re-running without needing to make again. So optional code below to handle those optons. (Otherwise, in the way the code is in the cell, the cell runs fine without doing anything in present form.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if need to read in the GIANT lookup dictonary\n",
    "'''\n",
    "import pickle\n",
    "with open(\"look_up_dict_for_h2nh3_all_14188_Uniprot_ACCs.pkl\", \"rb\") as f:\n",
    "        merged_lookup_dict = pickle.load(f)\n",
    "len(list(merged_lookup_dict.keys()))\n",
    "'''\n",
    "\n",
    "# if need to save the GIANT lookup dictionary again for some reason\n",
    "'''\n",
    "import pickle\n",
    "with open(\"look_up_dict_for_h2nh3_all_14188_Uniprot_ACCs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(merged_lookup_dict, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use lookup table to fix and balance the two columns, `'Uniprot_ACCs'` & `'genenames'`\n",
    "\n",
    "This is a step towards making a better CSV that adheres close to the author-provided one but follows better data management practices to make it easier to use Pandas `explode()` the way I had been when I though the two columns were in-order matched and I had not realized the extent of special cases buried in the data.\n",
    "\n",
    "Also will do some accounting along the way so I can have more numbers to relate what was going on in original CSV. One aspect of this will be to assess how many special cases there are and make it easy to find them more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"look_up_dict_for_h2nh3_all_14188_Uniprot_ACCs.pkl\", \"rb\") as f:\n",
    "        merged_lookup_dict = pickle.load(f)\n",
    "len(list(merged_lookup_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found **later** needed some additional ones added that have gene names in the `genename` column but no corresponding identifier in the `Uniprot_ACCs` column , like so:\n",
    "\n",
    "```text\n",
    "HuMAP2_06154,4,  Q86YV6 Q9H7B4   Q9H9G7,HSP90AA5P HSP90AB2P MYLK4 SMYD3 HSP90AB3P HSP90AB4P AGO3\n",
    "HuMAP2_00547,5, P58876 P16104 P23527 Q96T23 Q6ZRQ5 Q8IUE6,H3-2 HIST1H2BD H2AFX HIST1H2BO RSF1 MMS22L HIST2H2AB\n",
    "HuMAP2_01550,4,Q8NB90  Q9BW66 Q9BVQ7 Q9NX04,SPATA5 RIPK4 CINP SPATA5L1 C1orf109\n",
    "```\n",
    "\n",
    "Next cell handles the several cases of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add handling for following:\n",
    "`HSP90AB2P` corresponds to UniProt accension `Q58FF8`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AB4P` corresponds to UniProt accension `Q58FF6`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AB3P` corresponds to UniProt accension `Q58FF7`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`HSP90AA5P` corresponds to UniProt accension `Q58FG0`, but that isn't present there. Instead weird gap seen between `Q9H7B4   Q9H9G7`?\n",
    "`H3-2` that seems to correspond to `Q5TEC6`\n",
    "`RIPK4` seems to be the one missing a corresponding entry in the `Uniprot_ACCs` column. It seems it should be `P57078`.\n",
    "`ZNF678` that seems to correspond to `Q5SXM1`\n",
    "`C4orf48` should have a matching entry of `Q5BLP8`. \n",
    "WASH6P Q9NQA3 \n",
    "IGHG4 P01861\n",
    "LINC01587 Q99440\n",
    "FAM90A26 D6RGX4\n",
    "FAM90A5P A8MXJ8\n",
    "MSL3P1 P0C860\n",
    "PI4KAP1 Q8N8J0\n",
    "ZRSR2P1 Q15695\n",
    "DENND10P1 Q6NSW5\n",
    "LILRB2 Q8N423\n",
    "ALDH3B2 P48448\n",
    "FAM153CP A0AAQ5BID4\n",
    "FAM153B P0C7A2\n",
    "FRG1BP SPECIAL_HGNC15792 (couldn't find one but this is HGNC entry accession)\n",
    "TUBB7P SPECIAL_HGNC12413 (couldn't find one but this is HGNC entry accession)\n",
    "CHCHD2P9 Q5T1J5\n",
    "OFCC1 Q8IZS5\n",
    "SNRPGP15 A8MWD9\n",
    "IGHA1 P01876\n",
    "NME2P1 O60361\n",
    "DSCR4 P56555\n",
    "PABPC4L P0CB38\n",
    "IGLC7 A0M8Q6\n",
    "SSX6P Q7RTT6\n",
    "GPATCH4 Q5T3I0\n",
    "CEP170P1 Q96L14\n",
    "FRMD8P1 Q9BZ68\n",
    "CROCCP2 Q86T23\n",
    "OR4K3 Q96R72\n",
    "FBXL18 Q96ME1\n",
    "HMGB1P1 B2RPK0\n",
    "FBLL1 A6NHQ2\n",
    "WASH3P C4AMC7\n",
    "ABHD18 Q0P651\n",
    "PZP P20742\n",
    "IGLC3 P0DOY3\n",
    "HECTD4 Q9Y4D8\n",
    "SOWAHA Q2M3V2\n",
    "SIGLEC16 A6NMB1\n",
    "TEX15 Q9BXT5\n",
    "PPP1R15B Q5SWA1\n",
    "PRSS46P E5RG02\n",
    "PLEKHA8P1 O95397\n",
    "SAC3D1 A6NKF1\n",
    "KIR3DP1 A0A0G2JN01\n",
    "MRPL45 Q9BRJ2\n",
    "NEDD8-MDP1 E9PL57\n",
    "HSPA7 P48741\n",
    "ARMCX4 Q5H9R4\n",
    "IGHM P01871\n",
    "PIPSL A2A3N6\n",
    "APOBEC3D Q96AK3\n",
    "POTEKP Q9BYX7\n",
    "IGKC P01834\n",
    "CIRBP-AS1 Q8TBR5\n",
    "ZSCAN12 O43309\n",
    "APOA4 P06727\n",
    "IGHG1 P01857\n",
    "CTSL3P Q5NE16\n",
    "ZNF724 A8MTY0\n",
    "PRKY O43930\n",
    "NPIPB7 O75200\n",
    "DHRS4L2 Q6PKH6\n",
    "HLA-H P01893\n",
    "IGHA2 P01877\n",
    "PRR5-ARHGAP8 B1AHC3\n",
    "EP400P1 Q6ZTU2\n",
    "PATJ Q8NI35\n",
    "LILRB3 O75022\n",
    "TRAC P01848\n",
    "POM121C A8CG34\n",
    "IGLC2 P0DOY2\n",
    "LILRA6 Q6PI73\n",
    "IGHG3 P01860\n",
    "IGHG2 P01859\n",
    "RUNDC1 Q96C34\n",
    "RPS26P11 Q5JNZ5\n",
    "HSP90AA4P Q58FG1\n",
    "LINC01667 SPECIAL_HGNC52455 (couldn't find one but this is HGNC entry accession)\n",
    "LOC100507703  SPECIAL_HLA-A-related   (https://www.ncbi.nlm.nih.gov/gene/100507703 says LOC100507703 replaced with Gene ID: 3105 but that is HLA-A that is already list in complex)\n",
    "KLRA1P O75889\n",
    "MRRFP1 SPECIAL_HGNC35238 (couldn't find one but this is HGNC entry accession)\n",
    "INTS4P2 SPECIAL_HGNC22351 (couldn't find one but this is HGNC entry accession)\n",
    "C9orf106 Q8NAJ2\n",
    "GGT2 P36268\n",
    "GK3P Q14409\n",
    "RPSAP58 A0A8I5KQE6\n",
    "USP41 SPECIAL_HGNC20070 (couldn't find one but this is HGNC entry accession)\n",
    "'''\n",
    "special_genename_lookup_dict = {}\n",
    "special_genename_lookup_dict['HSP90AB4P'] = 'Q58FF6'\n",
    "special_genename_lookup_dict['HSP90AB3P'] = 'Q58FF7'\n",
    "special_genename_lookup_dict['HSP90AB2P'] = 'Q58FF8'\n",
    "special_genename_lookup_dict['HSP90AA5P'] = 'Q58FG0'\n",
    "special_genename_lookup_dict['H3-2'] = 'Q5TEC6'\n",
    "special_genename_lookup_dict['RIPK4'] = 'P57078'\n",
    "special_genename_lookup_dict['ZNF678'] = 'Q5SXM1'\n",
    "special_genename_lookup_dict['C4orf48'] = 'Q5BLP8'\n",
    "special_genename_lookup_dict['WASH6P'] = 'Q9NQA3'\n",
    "special_genename_lookup_dict['IGHG4'] = 'P01861'\n",
    "special_genename_lookup_dict['LINC01587'] = 'Q99440'\n",
    "special_genename_lookup_dict['FAM90A26'] = 'D6RGX4'\n",
    "special_genename_lookup_dict['FAM90A5P'] = 'A8MXJ8'\n",
    "special_genename_lookup_dict['MSL3P1'] = 'P0C860'\n",
    "special_genename_lookup_dict['PI4KAP1'] = 'Q8N8J0'\n",
    "special_genename_lookup_dict['ZRSR2P1'] = 'Q15695'\n",
    "special_genename_lookup_dict['DENND10P1'] = 'Q6NSW5'\n",
    "special_genename_lookup_dict['LILRB2'] = 'Q8N423'\n",
    "special_genename_lookup_dict['ALDH3B2'] = 'P48448'\n",
    "special_genename_lookup_dict['FAM153CP'] = 'A0AAQ5BID4'\n",
    "special_genename_lookup_dict['FAM153B'] = 'P0C7A2'\n",
    "special_genename_lookup_dict['FRG1BP'] = 'SPECIAL_HGNC15792' #couldn't find one but this is HGNC entry accession\n",
    "special_genename_lookup_dict['TUBB7P'] = 'SPECIAL_HGNC12413' #couldn't find one but this is HGNC entry accession\n",
    "special_genename_lookup_dict['CHCHD2P9'] = 'Q5T1J5'\n",
    "special_genename_lookup_dict['OFCC1'] = 'Q8IZS5'\n",
    "special_genename_lookup_dict['SNRPGP15'] = 'A8MWD9'\n",
    "special_genename_lookup_dict['IGHA1'] = 'P01876'\n",
    "special_genename_lookup_dict['NME2P1'] = 'O60361'\n",
    "special_genename_lookup_dict['DSCR4'] = 'P56555'\n",
    "special_genename_lookup_dict['PABPC4L'] = 'P0CB38'\n",
    "special_genename_lookup_dict['IGLC7'] = 'A0M8Q6'\n",
    "special_genename_lookup_dict['SSX6P'] = 'Q7RTT6'\n",
    "special_genename_lookup_dict['GPATCH4'] = 'Q5T3I0'\n",
    "special_genename_lookup_dict['CEP170P1'] = 'Q96L14'\n",
    "special_genename_lookup_dict['FRMD8P1'] = 'Q9BZ68'\n",
    "special_genename_lookup_dict['CROCCP2'] = 'Q86T23'\n",
    "special_genename_lookup_dict['OR4K3'] = 'Q96R72'\n",
    "special_genename_lookup_dict['FBXL18'] = 'Q96ME1'\n",
    "special_genename_lookup_dict['HMGB1P1'] = 'B2RPK0'\n",
    "special_genename_lookup_dict['FBLL1'] = 'A6NHQ2'\n",
    "special_genename_lookup_dict['WASH3P'] = 'C4AMC7'\n",
    "special_genename_lookup_dict['ABHD18'] = 'Q0P651'\n",
    "special_genename_lookup_dict['PZP'] = 'P20742'\n",
    "special_genename_lookup_dict['IGLC3'] = 'P0DOY3'\n",
    "special_genename_lookup_dict['HECTD4'] = 'Q9Y4D8'\n",
    "special_genename_lookup_dict['SOWAHA'] = 'Q2M3V2'\n",
    "special_genename_lookup_dict['SIGLEC16'] = 'A6NMB1'\n",
    "special_genename_lookup_dict['TEX15'] = 'Q9BXT5'\n",
    "special_genename_lookup_dict['PPP1R15B'] = 'Q5SWA1'\n",
    "special_genename_lookup_dict['PRSS46P'] = 'E5RG02'\n",
    "special_genename_lookup_dict['PLEKHA8P1'] = 'O95397'\n",
    "special_genename_lookup_dict['SAC3D1'] = 'A6NKF1'\n",
    "special_genename_lookup_dict['KIR3DP1'] = 'A0A0G2JN01'\n",
    "special_genename_lookup_dict['MRPL45'] = 'Q9BRJ2'\n",
    "special_genename_lookup_dict['NEDD8-MDP1'] = 'E9PL57'\n",
    "special_genename_lookup_dict['HSPA7'] = 'P48741'\n",
    "special_genename_lookup_dict['ARMCX4'] = 'Q5H9R4'\n",
    "special_genename_lookup_dict['IGHM'] = 'P01871'\n",
    "special_genename_lookup_dict['PIPSL'] = 'A2A3N6'\n",
    "special_genename_lookup_dict['APOBEC3D'] = 'Q96AK3'\n",
    "special_genename_lookup_dict['POTEKP'] = 'Q9BYX7'\n",
    "special_genename_lookup_dict['IGKC'] = 'P01834'\n",
    "special_genename_lookup_dict['CIRBP-AS1'] = 'Q8TBR5'\n",
    "special_genename_lookup_dict['ZSCAN12'] = 'O43309'\n",
    "special_genename_lookup_dict['APOA4'] = 'P06727'\n",
    "special_genename_lookup_dict['IGHG1'] = 'P01857'\n",
    "special_genename_lookup_dict['CTSL3P'] = 'Q5NE16'\n",
    "special_genename_lookup_dict['ZNF724'] = 'A8MTY0'\n",
    "special_genename_lookup_dict['PRKY'] = 'O43930'\n",
    "special_genename_lookup_dict['NPIPB7'] = 'O75200'\n",
    "special_genename_lookup_dict['DHRS4L2'] = 'Q6PKH6'\n",
    "special_genename_lookup_dict['HLA-H'] = 'P01893'\n",
    "special_genename_lookup_dict['IGHA2'] = 'P01877'\n",
    "special_genename_lookup_dict['PRR5-ARHGAP8'] = 'B1AHC3'\n",
    "special_genename_lookup_dict['EP400P1'] = 'Q6ZTU2'\n",
    "special_genename_lookup_dict['PATJ'] = 'Q8NI35'\n",
    "special_genename_lookup_dict['LILRB3'] = 'O75022'\n",
    "special_genename_lookup_dict['TRAC'] = 'P01848'\n",
    "special_genename_lookup_dict['POM121C'] = 'A8CG34'\n",
    "special_genename_lookup_dict['IGLC2'] = 'P0DOY2'\n",
    "special_genename_lookup_dict['LILRA6'] = 'Q6PI73'\n",
    "special_genename_lookup_dict['IGHG3'] = 'P01860'\n",
    "special_genename_lookup_dict['IGHG2'] = 'P01859'\n",
    "special_genename_lookup_dict['RUNDC1'] = 'Q96C34'\n",
    "special_genename_lookup_dict['RPS26P11'] = 'Q5JNZ5'\n",
    "special_genename_lookup_dict['HSP90AA4P'] = 'Q58FG1'\n",
    "special_genename_lookup_dict['LINC01667'] = 'SPECIAL_HGNC52455' #couldn't find one but this is HGNC entry accession\n",
    "special_genename_lookup_dict['LOC100507703'] = 'SPECIAL_HLA-A-related' #couldn't find one LOC100507703, seems HLA-A-related \n",
    "special_genename_lookup_dict['KLRA1P'] = 'O75889' \n",
    "special_genename_lookup_dict['MRRFP1'] = 'SPECIAL_HGNC35238' #couldn't find one but this is HGNC entry accession\n",
    "special_genename_lookup_dict['INTS4P2'] = 'SPECIAL_HGNC22351' #couldn't find one but this is HGNC entry accession\n",
    "special_genename_lookup_dict['C9orf106'] = 'Q8NAJ2' \n",
    "special_genename_lookup_dict['GGT2'] = 'P36268' \n",
    "special_genename_lookup_dict['GK3P'] = 'Q14409'\n",
    "special_genename_lookup_dict['RPSAP58'] = 'A0A8I5KQE6'\n",
    "special_genename_lookup_dict['USP41'] = 'SPECIAL_HGNC20070' #couldn't find one but this is HGNC entry accession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ready to get started fixing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using the `merged_lookup_dict` go through `rd_df` dataframe row by row and \n",
    "# replace the column Uniprot_ACCs and genenames with in-order matched, balanced\n",
    "# versions and do accounting on them to track things along the way.\n",
    "# The tracking dataframe that will result will be separate from the main one \n",
    "# because I need that to be good to save and replace the author-provided `hu.MAP3.0_complexes_wConfidenceScores_total15326_wGenenames_20240922.csv`\n",
    "lookup_dict = merged_lookup_dict\n",
    "fixed_df = rd_df.copy()\n",
    "tracker_results_df = rd_df.copy()\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        self.tracking_list = []\n",
    "\n",
    "def make_ordered_fix_and_collect_info_about_balance(row, tracker):\n",
    "    # for each row iterate on the identfiers in the column Uniprot_ACCs and \n",
    "    # account for the corresponding genename value in the genenames column. \n",
    "    # THIS WILL PRODUCED SAME NUMBER IN EACH COLUMN - so they are BALANCED in \n",
    "    # new version.\n",
    "    # Do some tracking for accounting, too:\n",
    "    # What is left? If anything is left then `genenames_had_unaccounted_for`\n",
    "    # Also note if matching originally. Or if even balanced originally. (Note\n",
    "    # that 'balanced originally' will take into account what I know about some \n",
    "    # Uniprot accensions corresponding to two genenames to produce the ones like \n",
    "    # `SLX1A; SLX1B` or `HSFY1; HSFY2` that have the semi-colon between the two \n",
    "    # related genemaes for the single Uniprot_ACC.\n",
    "    # Or if one of the semi-colons is involved, etc.\n",
    "    new_Uniprot_ACCs_list = []\n",
    "    new_genenames_list = []\n",
    "    original_ACCs_string = row['Uniprot_ACCs']\n",
    "    original_ACCs_as_list = row['Uniprot_ACCs'].split()\n",
    "    original_ACCs_as_list = list(set(original_ACCs_as_list)) #do this to remove duplicates, see above & `Check_for_duplicates_in_author_provided_hu.MAP2.0_csv.ipynb` showing quite a few occurences of duplicates in rows of raw data\n",
    "    original_genenames_string = row['genenames']\n",
    "    original_genenames_as_list = row['genenames'].split()\n",
    "    # if original `genenames` has semi-colons, fix list based on what I had seen\n",
    "    # in analysis earlier in this notebook, so what looks like two separated by\n",
    "    # a `; ` are one without a space at all in the list. This is necessary to \n",
    "    # check the number of items balanced in each column later for \n",
    "    # 'balanced_originally' assessnent\n",
    "    if ';' in original_genenames_string:\n",
    "        # then fix the list\n",
    "        adjusted_original_genenames_as_list = []\n",
    "        i = 0\n",
    "        while i < len(original_genenames_as_list):\n",
    "            if original_genenames_as_list[i].endswith(';'):\n",
    "                new_string = original_genenames_as_list[i] + original_genenames_as_list[i+1]\n",
    "                adjusted_original_genenames_as_list.append(new_string)\n",
    "                i += 2  # Skip the next element because already merged it into one before it to make one genename text string corresponding to the ID for a specific single Uniprot_ACC; for checking for balance\n",
    "            else:\n",
    "                adjusted_original_genenames_as_list.append(original_genenames_as_list[i])\n",
    "                i += 1\n",
    "        original_genenames_as_list = adjusted_original_genenames_as_list # now set the list to the fixed one\n",
    "    what_remains = original_genenames_string # will be used to see if any genenames content not accounted for by content in Uniprot_ACCs column\n",
    "    matching_originally = False # set this and only change if established below\n",
    "    balanced_originally = False # set this and only change if established below\n",
    "    involves_semicolon = False # set this and only change if established below\n",
    "    SPECIAL_involved = False # set this and only change if established below\n",
    "    genenames_had_unaccounted_for = False # set this and only change if established below\n",
    "    what_genenames_had_unaccounted_for = \"NOTHING\" # set this and only change if established below\n",
    "\n",
    "    # Sort the original_ACCs_as_list based on the length of their corresponding genenames\n",
    "    # in lookup_dict (longest first)\n",
    "    sorted_original_ACCs = sorted(\n",
    "        original_ACCs_as_list,\n",
    "        key=lambda x: len(lookup_dict[x]),\n",
    "        reverse=True\n",
    "    )\n",
    "    # Now process in order of longest genename to shortest so for related genes like `TBL1X` and `TBL1XR1`, I don't end up removing `TBL1X` from `TBL1XR1` and just leave `R1` when making `what_remains`.\n",
    "    for original_ACC in sorted_original_ACCs:\n",
    "        if original_ACC == '645345': # handle this special case I noted where Uniprot_ACCs doesn't match a UniProt accessions; and this way if authors ever fix this won't happen and won't affect anything\n",
    "            new_Uniprot_ACCs_list.append('Q5T1J5')\n",
    "        else:\n",
    "            new_Uniprot_ACCs_list.append(original_ACC) # TYPICAL FOR ALL EXCEPT ONE!\n",
    "        matched_genename = lookup_dict[original_ACC]\n",
    "        new_genenames_list.append(matched_genename.replace(\" \",\"\")) # the replace will remove the space after the semi-colon for any that have that; maybe I could have done it when I made the lookup table but I had decided at the time to keep the option to adhere closer to the orginal author-provided CSV representation but now realize when 'exploding' the contents of the columns to have one identifier pairing per row, the space after the semi-colon will be an issue in the way I did it based on my earlier assessment of the author-provided CSV. On the plus side of leaving it in, when I remove the matching text from the text in the genenames column to see what may remain unaccounted for based on the IDs in the Uniprot_ACCs columns, I don't have to specially add back in the space to match the original form.\n",
    "        # While doing this iterating, start removing the accounted for \n",
    "        # identifiers from the second column string to end up with what is \n",
    "        # unaccounted for in the genenames column by the matching Uniprot_ACCs.\n",
    "        # Importantly, only replace the first occurrence of the exact genename; \n",
    "        # this and the sorting I did above will help with related genes like \n",
    "        # `TBL1X` and `TBL1XR1`.\n",
    "        parts = what_remains.split()\n",
    "        if lookup_dict[original_ACC] in parts:\n",
    "            parts.remove(lookup_dict[original_ACC]) #want the one that comes up\n",
    "            # from the lookup_dict matching so that ones that have semi-colon in \n",
    "            # them removes both of the two name ones at the same time; the one \n",
    "            # I put in `new_genenames_list` above had the space removed and so \n",
    "            # if used that one the semi-colon related ones won't get deleted \n",
    "            # from what_remains properly and end up being specified erroneously \n",
    "            # as remaining\n",
    "            what_remains = \" \".join(parts)\n",
    "        # need special handling for the cases where there is a semi-colon in the\n",
    "        # matched genename and note want the one that comes up from the \n",
    "        # lookup_dict matching so that ones that have semi-colon in them removes \n",
    "        # both of the two name ones at the same time; the one. I put in \n",
    "        # `new_genenames_list` above had the space removed and so if used that \n",
    "        # one the semi-colon related ones won't get deleted from what_remains \n",
    "        # properly and end up being specified erroneously as remaining.\n",
    "        '''\n",
    "        if ';' in matched_genename and matched_genename.count(';') == 1: # some have more than one semi-colon and mostly I'll handle hardcoding below\n",
    "            # Handle the semicolon case by finding and removing the exact pair\n",
    "            parts = what_remains.split()\n",
    "            i = 0\n",
    "            while i < len(parts)-1:\n",
    "                if parts[i].endswith(';'):\n",
    "                    potential_pair = parts[i] + ' ' + parts[i+1]\n",
    "                    if potential_pair == matched_genename:\n",
    "                        # Remove both parts of the pair\n",
    "                        parts.pop(i)\n",
    "                        parts.pop(i)  # don't increment i since we removed two items\n",
    "                        break\n",
    "                    else:\n",
    "                        i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "            what_remains = ' '.join(parts)\n",
    "        '''\n",
    "        if ';' in matched_genename: # Handle gene names with semi-colon different for hu.MAP 2.0\n",
    "            # Handle the semicolon case by finding and removing the first part of name\n",
    "            parts = what_remains.split()\n",
    "            first_part_matched_genename = matched_genename.split(';')[0]\n",
    "            if first_part_matched_genename in parts:\n",
    "                parts.remove(first_part_matched_genename)\n",
    "                what_remains = ' '.join(parts)\n",
    "        elif original_ACC in ['O15482','P23610','P62805','P68431','Q71DI3','P62807','P62807','P0C0S8','Q6ZMK1','P04745','P0DN76','A6NLF2','B9ZVM9','Q9Y4X1','Q12799','Q5VWM5','P0DN79','P0DN76']:\n",
    "            # handle some special cases where there's semi-colons (plus a few additional cpecial cases) so default below won't work and so few that it isn't worth working out programmatically\n",
    "            # SET UP TO Handle several special cases I noted, so proper text gets removed and don't add extra SPECIAL case to result CSV:\n",
    "            if original_ACC == 'O15482':\n",
    "                #matched_genename = 'TEX28; TEX28P1; TEX28P2' #for hu.MAP 3; ones with more than a single semi-colon. Just going to hardcode handling removal so not tagged as unaccounted for.\n",
    "                matched_genename = 'TEX28'#for hu.MAP 2\n",
    "            if original_ACC == 'P23610':\n",
    "                #matched_genename = 'F8A1; F8A2; F8A3' #for hu.MAP 3\n",
    "                matched_genename = 'F8A1' #for hu.MAP 2\n",
    "            if original_ACC == 'P62805':\n",
    "                #matched_genename = 'H4C1; H4C2; H4C3; H4C4; H4C5; H4C6; H4C8; H4C9; H4C11; H4C12; H4C13; H4C14; H4C15; H4C16' #for hu.MAP 3\n",
    "                matched_genename = 'H4C1' #for hu.MAP 2\n",
    "            if original_ACC == 'P68431':\n",
    "                #matched_genename = 'H3C1; H3C2; H3C3; H3C4; H3C6; H3C7; H3C8; H3C10; H3C11; H3C12' #for hu.MAP 3\n",
    "                matched_genename = 'H3C1' #for hu.MAP 2\n",
    "            if original_ACC == 'Q71DI3':\n",
    "                matched_genename = 'H3C15; H3C14; H3C13'\n",
    "            if original_ACC == 'P62807':\n",
    "                matched_genename = 'H2BC4; H2BC6; H2BC7; H2BC8; H2BC10'\n",
    "            if original_ACC == 'P0C0S8':\n",
    "                #matched_genename = 'H2AC11; H2AC13; H2AC15; H2AC16; H2AC17' #for hu.MAP 3\n",
    "                matched_genename = 'H2AC11' #for hu.MAP 2\n",
    "            if original_ACC == 'Q6ZMK1':\n",
    "                matched_genename = 'CYHR1' # They use 'CYHR1' which doesn't exist in UniProt now, see https://www.uniprot.org/uniprotkb/Q6ZMK1/history ;'This entry has now been demerged. Its accession has been set as secondary accession in P0DTL5 and P0DTL6.'\n",
    "            if original_ACC == 'P04745':\n",
    "                matched_genename = 'AMY1A' # They use 'AMY1A' which doesn't exist in UniProt now, see https://www.uniprot.org/uniprotkb/P04745/history ;'This entry has now been demerged. Its accession has been set as secondary accession in P0DTE7, P0DTE8, and P0DUB6'\n",
    "            if original_ACC == 'P0DN76':\n",
    "                matched_genename = 'U2AF1L5' # They use 'U2AF1L5' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'A6NLF2':\n",
    "                matched_genename = 'ELOA3D' # They use 'ELOA3D' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'B9ZVM9':\n",
    "                matched_genename = 'TCP10L2' # They use 'TCP10L2' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'Q9Y4X1':\n",
    "                matched_genename = 'UGT2A1' # They use 'UGT2A1' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'Q12799':\n",
    "                matched_genename = 'TCP10' # They use 'TCP10' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'Q5VWM5':\n",
    "                matched_genename = 'PRAMEF9' # They use 'PRAMEF9' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            if original_ACC == 'P0DN79':\n",
    "                matched_genename = 'CBSL' # They use 'CBSL' which doesn't exist in UniProt now; like case for `CYHR1` and `AMY1A` above\n",
    "            # END SET UP FOR SEVERAL SPECIAL CASES WITH MANY SEMI-COLONS + other special cases where ACC is distinct\n",
    "            what_remains = what_remains.replace(matched_genename,'')\n",
    "        else:\n",
    "            # Handle single genename case (when there is no semi-colon)\n",
    "            parts = what_remains.split()\n",
    "            # SET UP TO Handle several special cases I noted, so proper text gets removed and don't add extra SPECIAL case to resulting CSV:\n",
    "            if matched_genename == 'SLC66A1LP':\n",
    "                matched_genename = 'SLC66A1L' # makes it match what author provided file had for that one; they used one of its few synonyms\n",
    "            if matched_genename == 'PRP4K':\n",
    "                matched_genename = 'PRPF4B' # makes it match what author provided file had for that one; they used one of its few synonyms\n",
    "            if matched_genename == 'CFAP263':\n",
    "                matched_genename = 'CCDC113' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CFAP337':\n",
    "                matched_genename = 'WDR49' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FERRY3':\n",
    "                matched_genename = 'C12orf4' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CFAP184':\n",
    "                matched_genename = 'CCDC96' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GARRE1':\n",
    "                matched_genename = 'KIAA0355' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SKIC8':\n",
    "                matched_genename = 'WDR61' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FHIP1B':\n",
    "                matched_genename = 'FAM160A2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FHIP1A':\n",
    "                matched_genename = 'FAM160A1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IFT70B':\n",
    "                matched_genename = 'TTC30B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IFT70A':\n",
    "                matched_genename = 'TTC30A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IFT56':\n",
    "                matched_genename = 'TTC26' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2AC20':\n",
    "                matched_genename = 'HIST2H2AC' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'STEEP1':\n",
    "                matched_genename = 'CXorf56' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ATP5MK':\n",
    "                matched_genename = 'ATP5MD' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MACIR':\n",
    "                matched_genename = 'C5orf30' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CYRIA':\n",
    "                matched_genename = 'FAM49A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CYRIB':\n",
    "                matched_genename = 'FAM49B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'UQCC6':\n",
    "                matched_genename = 'C12orf73' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2AC21':\n",
    "                matched_genename = 'HIST2H2AB' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'POLR1H':\n",
    "                matched_genename = 'ZNRD1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'POLR1G':\n",
    "                matched_genename = 'CD3EAP' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'POLR1F':\n",
    "                matched_genename = 'TWISTNB' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'RUSF1':\n",
    "                matched_genename = 'C16orf58' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GARIN1A':\n",
    "                matched_genename = 'FAM71F2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MARCHF5':\n",
    "                matched_genename = 'MARCH5' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H1-10':\n",
    "                matched_genename = 'H1FX' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H1-6':\n",
    "                matched_genename = 'HIST1H1T' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CEP20':\n",
    "                matched_genename = 'FOPNL' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ODAD3':\n",
    "                matched_genename = 'CCDC151' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SKIC2':\n",
    "                matched_genename = 'SKIV2L' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MIX23':\n",
    "                matched_genename = 'CCDC58' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2BC17':\n",
    "                matched_genename = 'HIST1H2BO' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2AX':\n",
    "                matched_genename = 'H2AFX' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2BC5':\n",
    "                matched_genename = 'HIST1H2BD' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ARB2A':\n",
    "                matched_genename = 'FAM172A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MTCL2':\n",
    "                matched_genename = 'SOGA1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PSME3IP1':\n",
    "                matched_genename = 'FAM192A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H2BC18':\n",
    "                matched_genename = 'HIST2H2BF' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'YJU2B':\n",
    "                matched_genename = 'CCDC130' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CILK1':\n",
    "                matched_genename = 'ICK' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GFUS':\n",
    "                matched_genename = 'TSTA3' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ADGRE5':\n",
    "                matched_genename = 'CD97' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CERT1':\n",
    "                matched_genename = 'CERT' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ODAD2':\n",
    "                matched_genename = 'ARMC4' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ODAD4':\n",
    "                matched_genename = 'TTC25' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MTCL3':\n",
    "                matched_genename = 'SOGA3' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TRAPPC14':\n",
    "                matched_genename = 'MAP11' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SCAND3':\n",
    "                matched_genename = 'ZBED9' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CDIN1':\n",
    "                matched_genename = 'C15orf41' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CSTPP1':\n",
    "                matched_genename = 'C11orf49' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PHB1':\n",
    "                matched_genename = 'PHB' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ENTREP3':\n",
    "                matched_genename = 'FAM189B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FAM200C':\n",
    "                matched_genename = 'ZBED8' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PABIR1':\n",
    "                matched_genename = 'FAM122A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'VCF1':\n",
    "                matched_genename = 'FAM104A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PALS1':\n",
    "                matched_genename = 'MPP5' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DYNC2I2':\n",
    "                matched_genename = 'WDR34' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DYNLT2B':\n",
    "                matched_genename = 'TCTEX1D2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DYNC2I1':\n",
    "                matched_genename = 'WDR60' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IFTAP':\n",
    "                matched_genename = 'C11orf74' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'RARS1':\n",
    "                matched_genename = 'RARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'LARS1':\n",
    "                matched_genename = 'LARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'EPRS1':\n",
    "                matched_genename = 'EPRS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'EPRS1':\n",
    "                matched_genename = 'QARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MARS1':\n",
    "                matched_genename = 'MARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IARS1':\n",
    "                matched_genename = 'IARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DARS1':\n",
    "                matched_genename = 'DARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CIMIP4':\n",
    "                matched_genename = 'TEX33' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'WARS1':\n",
    "                matched_genename = 'WARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H1-7':\n",
    "                matched_genename = 'H1FNT' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PABIR2':\n",
    "                matched_genename = 'FAM122B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'HYCC1':\n",
    "                matched_genename = 'FAM126A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'METTL13':\n",
    "                matched_genename = 'EEF1AKNMT' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CRIPTO':\n",
    "                matched_genename = 'TDGF1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'AIRIM':\n",
    "                matched_genename = 'C1orf109' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'AFG2B':\n",
    "                matched_genename = 'SPATA5L1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'AFG2A':\n",
    "                matched_genename = 'SPATA5' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PALS2':\n",
    "                matched_genename = 'MPP6' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CARS1':\n",
    "                matched_genename = 'CARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TARS3':\n",
    "                matched_genename = 'TARSL2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MIDEAS':\n",
    "                matched_genename = 'ELMSAN1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ZNG1C':\n",
    "                matched_genename = 'CBWD3' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ARK2N':\n",
    "                matched_genename = 'C18orf25' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ZFHX3':\n",
    "                matched_genename = 'C16orf47' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CEP43':\n",
    "                matched_genename = 'FGFR1OP' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'VARS1':\n",
    "                matched_genename = 'VARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BBLN':\n",
    "                matched_genename = 'C9orf16' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DNAI3':\n",
    "                matched_genename = 'WDR63' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ATOSA':\n",
    "                matched_genename = 'FAM214A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CIMAP1D':\n",
    "                matched_genename = 'ODF3L2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BLTP2':\n",
    "                matched_genename = 'KIAA0100' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SARS1':\n",
    "                matched_genename = 'SARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PGAP6':\n",
    "                matched_genename = 'TMEM8A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SLX9':\n",
    "                matched_genename = 'FAM207A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CBY2':\n",
    "                matched_genename = 'SPERT' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BLTP3A':\n",
    "                matched_genename = 'UHRF1BP1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TASL':\n",
    "                matched_genename = 'CXorf21' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'UQCC4':\n",
    "                matched_genename = 'CCSMST1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DNAAF10':\n",
    "                matched_genename = 'WDR92' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GBA1':\n",
    "                matched_genename = 'GBA' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MARCHF9':\n",
    "                matched_genename = 'MARCH9' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TAFAZZIN':\n",
    "                matched_genename = 'TAZ' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'KICS2':\n",
    "                matched_genename = 'C12orf66' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'KGD4':\n",
    "                matched_genename = 'MRPS36' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FHIP2A':\n",
    "                matched_genename = 'FAM160B1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SAXO5':\n",
    "                matched_genename = 'TEX45' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SPMIP6':\n",
    "                matched_genename = 'SMRP1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'AARS1':\n",
    "                matched_genename = 'AARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ENTREP1':\n",
    "                matched_genename = 'FAM189A2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BMAL1':\n",
    "                matched_genename = 'ARNTL' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GET3':\n",
    "                matched_genename = 'ASNA1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TMT1A':\n",
    "                matched_genename = 'METTL7A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'YARS1':\n",
    "                matched_genename = 'YARS' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MACROH2A2':\n",
    "                matched_genename = 'H2AFY2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PHAF1':\n",
    "                matched_genename = 'C16orf70' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CIBAR1':\n",
    "                matched_genename = 'FAM92A' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DNAAF11':\n",
    "                matched_genename = 'LRRC6' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SANBR':\n",
    "                matched_genename = 'KIAA1841' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GET1':\n",
    "                matched_genename = 'WRB' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TMT1B':\n",
    "                matched_genename = 'METTL7B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MTARC2':\n",
    "                matched_genename = 'MARC2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SPRING1':\n",
    "                matched_genename = 'C12orf49' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'INTS15':\n",
    "                matched_genename = 'C7orf26' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'DNAAF8':\n",
    "                matched_genename = 'C16orf71' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'NTAQ1':\n",
    "                matched_genename = 'WDYHV1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'UTP25':\n",
    "                matched_genename = 'DIEXF' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BMAL2':\n",
    "                matched_genename = 'ARNTL2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'QNG1':\n",
    "                matched_genename = 'C9orf64' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'NHSL3':\n",
    "                matched_genename = 'KIAA1522' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SEPTIN4':\n",
    "                matched_genename = 'C17orf47' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SPMIP4':\n",
    "                matched_genename = 'C7orf31' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'PTGR3':\n",
    "                matched_genename = 'ZADH2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'EEIG2':\n",
    "                matched_genename = 'FAM102B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'IFT25':\n",
    "                matched_genename = 'HSPB11' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'NOPCHAP1':\n",
    "                matched_genename = 'C12orf45' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ZNG1A':\n",
    "                matched_genename = 'CBWD1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ZNG1B':\n",
    "                matched_genename = 'CBWD2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ZNG1F':\n",
    "                matched_genename = 'CBWD6' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'FHIP2B':\n",
    "                matched_genename = 'FAM160B2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MARCHF6':\n",
    "                matched_genename = 'MARCH6' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ELAPOR2':\n",
    "                matched_genename = 'KIAA1324L' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'GOLM2':\n",
    "                matched_genename = 'CASC4' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'STING1':\n",
    "                matched_genename = 'TMEM173' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'NHERF2':\n",
    "                matched_genename = 'SLC9A3R2' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'SKIC3':\n",
    "                matched_genename = 'TTC37' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'TMEM183BP':\n",
    "                matched_genename = 'TMEM183B' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BPNT2':\n",
    "                matched_genename = 'IMPAD1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MYL11':\n",
    "                matched_genename = 'MYLPF' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'MACROH2A1':\n",
    "                matched_genename = 'H2AFY' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'NHERF1':\n",
    "                matched_genename = 'SLC9A3R1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'BLTP3B':\n",
    "                matched_genename = 'UHRF1BP1L' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'ADISSP':\n",
    "                matched_genename = 'C20orf27' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'METTL25B':\n",
    "                matched_genename = 'RRNAD1' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'H3-5':\n",
    "                matched_genename = 'H3F3C' # makes it match what author provided file had for that one; they used its synonym\n",
    "            if matched_genename == 'CENATAC':\n",
    "                matched_genename = 'CCDC84' # makes it match what author provided file had for that one; they used what UniProt has under 'ORF names'\n",
    "            if matched_genename == 'MTNAP1':\n",
    "                matched_genename = 'C17orf80' # makes it match what author provided file had for that one; they used what UniProt has under 'ORF names'\n",
    "            if matched_genename == 'CEP15':\n",
    "                matched_genename = 'C3orf14' # makes it match what author provided file had for that one; they used what UniProt has under 'ORF names'\n",
    "            if matched_genename == 'PALM2AKAP2':\n",
    "                matched_genename = 'AKAP2' # makes it match what author provided file had for that one; they used an abbreviation of what UniProt has under 'Alternative names'\n",
    "            # END SET UP FOR SEVERAL SPECIAL CASES\n",
    "            if matched_genename in parts:\n",
    "                parts.remove(matched_genename)\n",
    "                what_remains = ' '.join(parts)\n",
    "\n",
    "    # now decide if anything extra has to be added to new_genenames_string by\n",
    "    # accounting for everything in original and adding what remains. Anything \n",
    "    # that gets added will need a 'SPECIAL_'-branded id placeholder added to the\n",
    "    # new_Uniprot_ACCs_list so that things remain balanced\n",
    "    if what_remains.strip():\n",
    "        genenames_had_unaccounted_for = True # set this for accounting\n",
    "        what_genenames_had_unaccounted_for = what_remains.strip() # set this for accounting\n",
    "        # now iterate on what splitting that string at the spaces returns and \n",
    "        # do special handling or if not in what needs special handling then\n",
    "        # add a corresponding 'SPECIAL_'-labeled entry placeholder \n",
    "        unaccounted_genenames_list = what_genenames_had_unaccounted_for.split()\n",
    "        for unaccounted_genename in unaccounted_genenames_list:\n",
    "            if unaccounted_genename in special_genename_lookup_dict:\n",
    "                new_Uniprot_ACCs_list.append(special_genename_lookup_dict[unaccounted_genename]) \n",
    "                new_genenames_list.append(unaccounted_genename)\n",
    "            else:\n",
    "                new_Uniprot_ACCs_list.append('SPECIAL_unaccounted_gene') # NOTE, I used iterating on running this function & finding this occurence in the data to progressively add handling two types of 'special cases' (one type being those with threee or more semi-colons and the other being where the author-provided file use a synonyms) and ultimately end up with NO instances of `SPECIAL_unaccounted_gene` being necessary in my fixed in-order matched, balanced verison of the data.\n",
    "                new_genenames_list.append(unaccounted_genename)\n",
    "    assert (len(new_Uniprot_ACCs_list) == len(new_genenames_list)) #sanity \n",
    "    # check; they definitely should balance still\n",
    "    new_Uniprot_ACCs_string = \" \".join(new_Uniprot_ACCs_list)\n",
    "    new_genenames_string = \" \".join(new_genenames_list)\n",
    "    # Now that done making in-order matched & balanced content, assign the \n",
    "    # appropriate text for those two columns to be returned when row returned at \n",
    "    # end of this entire function (before getting to end of this function \n",
    "    # though, will do some accounting)\n",
    "    row['Uniprot_ACCs'] = new_Uniprot_ACCs_string\n",
    "    row['genenames'] = new_genenames_string\n",
    "\n",
    "    # Check original state for collecting some details\n",
    "    '''\n",
    "    for idx,oa in enumerate(original_ACCs_as_list):\n",
    "        if original_genenames_as_list[idx] != lookup_dict[oa]:\n",
    "            matching_originally = False\n",
    "            break\n",
    "\n",
    "    matching_originally = all(\n",
    "        original_genenames_as_list[i] == lookup_dict[oa]\n",
    "        for i, oa in enumerate(original_ACCs_as_list)\n",
    "    )\n",
    "    '''\n",
    "    if len(original_ACCs_as_list) == len(original_genenames_as_list):\n",
    "        balanced_originally = True\n",
    "        # Only worth checking matching if balanced because otherwise get out `IndexError: list index out of range` as try to check `original_genenames_as_list[i]`\n",
    "        matching_originally = all(\n",
    "            original_genenames_as_list[i] == lookup_dict[oa]\n",
    "            for i, oa in enumerate(original_ACCs_as_list)\n",
    "        )\n",
    "    if ';' in row['genenames']:\n",
    "        involves_semicolon = True\n",
    "    # Plus check the new state as part of the information being collected; the rows in the tracker will correspond to the fixed CSV to be made and so it will be pertinent to the corresponding row and I don't want to pollute the one to be fixed\n",
    "    if any('SPECIAL' in item for item in new_Uniprot_ACCs_list + new_genenames_list):\n",
    "        SPECIAL_involved =True\n",
    "    # want to track, 'matching_originally','balanced originally','involves_semicolon','SPECIAL_involved','genenames_had_unaccounted_for','what_genenames_had_unaccounted_for'\n",
    "    # This way later can use count of the numbers there to easy to see what is going on.\n",
    "    tracker.tracking_list.append(\n",
    "                            {\n",
    "                            'matching_originally':matching_originally, \n",
    "                            'balanced_originally':balanced_originally, \n",
    "                            'involves_semicolon': involves_semicolon,\n",
    "                            'SPECIAL_involved': SPECIAL_involved,\n",
    "                            'genenames_had_unaccounted_for': genenames_had_unaccounted_for,\n",
    "                            'what_genenames_had_unaccounted_for': what_genenames_had_unaccounted_for\n",
    "                            })  # Append to the class attribute list a dictionary\n",
    "    return row\n",
    "\n",
    "tracker = Tracker()\n",
    "fixed_df = fixed_df.apply(make_ordered_fix_and_collect_info_about_balance, args=(tracker,), axis=1)\n",
    "# Save this as CSV\n",
    "fixed_df.to_csv(\"humap2_complexes_20200809InOrderMatched.csv\",index = False)\n",
    "# will add to the tracker df as columns the lists corresponding to the values of the list of dictionaries\n",
    "#matching_originally_values = [d['matching_originally'] for d in tracker]\n",
    "#balanced_originally_values = [d['balanced_originally'] for d in tracker]\n",
    "#involves_semicolon_values = [d['involves_semicolon'] for d in tracker]\n",
    "#SPECIAL_involved_values = [d['SPECIAL_involved'] for d in tracker]\n",
    "#genenames_had_unaccounted_for_values = [d['genenames_had_unaccounted_for'] for d in tracker]\n",
    "#what_genenames_had_unaccounted_for_values = [d['what_genenames_had_unaccounted_for'] for d in tracker]\n",
    "#tracker_results_df['matching_originally'] = matching_originally_values\n",
    "tracker_results_df['matching_originally'] = [d['matching_originally'] for d in tracker.tracking_list] \n",
    "tracker_results_df['balanced_originally'] = [d['balanced_originally'] for d in tracker.tracking_list] \n",
    "tracker_results_df['involves_semicolon'] = [d['involves_semicolon'] for d in tracker.tracking_list]\n",
    "tracker_results_df['SPECIAL_involved'] = [d['SPECIAL_involved'] for d in tracker.tracking_list]\n",
    "tracker_results_df['genenames_had_unaccounted_for'] = [d['genenames_had_unaccounted_for'] for d in tracker.tracking_list]\n",
    "tracker_results_df['what_genenames_had_unaccounted_for'] = [d['what_genenames_had_unaccounted_for'] for d in tracker.tracking_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HuMAP2_ID</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Uniprot_ACCs</th>\n",
       "      <th>genenames</th>\n",
       "      <th>matching_originally</th>\n",
       "      <th>balanced_originally</th>\n",
       "      <th>involves_semicolon</th>\n",
       "      <th>SPECIAL_involved</th>\n",
       "      <th>genenames_had_unaccounted_for</th>\n",
       "      <th>what_genenames_had_unaccounted_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuMAP2_00000</td>\n",
       "      <td>3</td>\n",
       "      <td>Q9BQS8 O95900</td>\n",
       "      <td>FYCO1 TRUB2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HuMAP2_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102</td>\n",
       "      <td>ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuMAP2_00002</td>\n",
       "      <td>5</td>\n",
       "      <td>Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...</td>\n",
       "      <td>RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HuMAP2_00003</td>\n",
       "      <td>5</td>\n",
       "      <td>Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...</td>\n",
       "      <td>VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuMAP2_00004</td>\n",
       "      <td>4</td>\n",
       "      <td>Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92</td>\n",
       "      <td>ZFAND2B KIF13B ASB7 OGN C8orf34</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HuMAP2_ID  Confidence  \\\n",
       "0  HuMAP2_00000           3   \n",
       "1  HuMAP2_00001           4   \n",
       "2  HuMAP2_00002           5   \n",
       "3  HuMAP2_00003           5   \n",
       "4  HuMAP2_00004           4   \n",
       "\n",
       "                                        Uniprot_ACCs  \\\n",
       "0                                      Q9BQS8 O95900   \n",
       "1          P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102   \n",
       "2  Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...   \n",
       "3  Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...   \n",
       "4                 Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92   \n",
       "\n",
       "                                           genenames  matching_originally  \\\n",
       "0                                        FYCO1 TRUB2                False   \n",
       "1            ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3                False   \n",
       "2  RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...                False   \n",
       "3  VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...                False   \n",
       "4                    ZFAND2B KIF13B ASB7 OGN C8orf34                False   \n",
       "\n",
       "   balanced_originally  involves_semicolon  SPECIAL_involved  \\\n",
       "0                 True               False             False   \n",
       "1                 True               False             False   \n",
       "2                 True               False             False   \n",
       "3                 True               False             False   \n",
       "4                 True               False             False   \n",
       "\n",
       "   genenames_had_unaccounted_for what_genenames_had_unaccounted_for  \n",
       "0                          False                            NOTHING  \n",
       "1                          False                            NOTHING  \n",
       "2                          False                            NOTHING  \n",
       "3                          False                            NOTHING  \n",
       "4                          False                            NOTHING  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initially running the above two steps with the code I worked out with the hu.MAP 3.0 data revealed some additional special cases lurking in the hu.MAP 2.0 data that I had to deal with:**\n",
    "(See the special handling code in the cell that two cells up for a full list; you'll need to compare that to the special handling section in  [the notebook 'Jupyter Notebook Standardizing Identifier Order In Adjacent Columns in hu.MAP2-provided CSV'](https://nbviewer.org/github/fomightez/humap3-binder/blob/main/additional_nbs/standardizing_initial_data/Standardizing_identifier_order_in_humap3-provided_csv.ipynb) to fully see the many of them but they fall into two categories so far: **more synonym names used** and **cases where genename is used for what is no longer in UniProt**.)  \n",
    "For dealing with the synonym names I had to add some special handling beyond that I had for the hu.MAP 3.0 data. To do that, I donwloaded an intermediate draft result, `DRAFThumap2_complexes_20200809InOrderMatched.csv`, that still had a lot (863 according to 'Find') of cases of `SPECIAL_unaccounted_gene` and I ran the following code to generate many more entries in the last section of special handling for accounting for what is missing in Uniprot_ACCs column, corresponding to `# makes it match what author provided file had for that one; they used its synonym`:\n",
    "The authors also had some like, `CYHR1` and `AMY1A`, that I found when developing automating making code dealing with synonyms handling. (These ones turned out to be revealed when coming across those without `'genes' in uniprot_record`.) A good percentage of these had been removed from UniProt and so no gene name even though the authors used one, and so I added special handling for the UniProt accessions for those, too. Plus, some of these involving gaps in the `Uniprot_ACCs` column seemed to just be where something got deleted as a large percent where pseudogenes but the genename remained.\n",
    "I added handling to the cell above to deal with many of these now, and so..... hopefully\n",
    "\n",
    "...eliminated all those, so at this point `genenames_had_unaccounted_for` and\t`what_genenames_had_unaccounted_for` are moot and can be removed from the tracker data.  \n",
    "Let's verify that here and then remove those two tracking columns. ??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genenames_had_unaccounted_for</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genenames_had_unaccounted_for  count\n",
       "0                          False   6736\n",
       "1                           True    229"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unf_count_df = tracker_results_df.copy().value_counts('genenames_had_unaccounted_for').reset_index()\n",
    "unf_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HuMAP2_ID</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Uniprot_ACCs</th>\n",
       "      <th>genenames</th>\n",
       "      <th>matching_originally</th>\n",
       "      <th>balanced_originally</th>\n",
       "      <th>involves_semicolon</th>\n",
       "      <th>SPECIAL_involved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuMAP2_00000</td>\n",
       "      <td>3</td>\n",
       "      <td>Q9BQS8 O95900</td>\n",
       "      <td>FYCO1 TRUB2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HuMAP2_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102</td>\n",
       "      <td>ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuMAP2_00002</td>\n",
       "      <td>5</td>\n",
       "      <td>Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...</td>\n",
       "      <td>RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HuMAP2_00003</td>\n",
       "      <td>5</td>\n",
       "      <td>Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...</td>\n",
       "      <td>VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuMAP2_00004</td>\n",
       "      <td>4</td>\n",
       "      <td>Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92</td>\n",
       "      <td>ZFAND2B KIF13B ASB7 OGN C8orf34</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HuMAP2_ID  Confidence  \\\n",
       "0  HuMAP2_00000           3   \n",
       "1  HuMAP2_00001           4   \n",
       "2  HuMAP2_00002           5   \n",
       "3  HuMAP2_00003           5   \n",
       "4  HuMAP2_00004           4   \n",
       "\n",
       "                                        Uniprot_ACCs  \\\n",
       "0                                      Q9BQS8 O95900   \n",
       "1          P08133 Q15797 Q99426 Q9H4M9 P68402 Q15102   \n",
       "2  Q93062 Q9NZC3 Q9UF11 Q15038 Q6ZRY4 A1KXE4 O432...   \n",
       "3  Q15836 Q16563 Q29983 Q8WUM9 O14974 Q9Y5Y0 Q149...   \n",
       "4                 Q8WV99 Q9NQT8 Q9H672 P20774 Q49A92   \n",
       "\n",
       "                                           genenames  matching_originally  \\\n",
       "0                                        FYCO1 TRUB2                False   \n",
       "1            ANXA6 SMAD1 TBCB EHD1 PAFAH1B2 PAFAH1B3                False   \n",
       "2  RBPMS GDE1 PLEKHB1 DAZAP2 RBPMS2 FAM168B RBFOX...                False   \n",
       "3  VAMP3 SYPL1 MICA SLC20A1 PPP1R12A FLVCR1 DRAP1...                False   \n",
       "4                    ZFAND2B KIF13B ASB7 OGN C8orf34                False   \n",
       "\n",
       "   balanced_originally  involves_semicolon  SPECIAL_involved  \n",
       "0                 True               False             False  \n",
       "1                 True               False             False  \n",
       "2                 True               False             False  \n",
       "3                 True               False             False  \n",
       "4                 True               False             False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_results_df = tracker_results_df.drop(columns=['genenames_had_unaccounted_for', 'what_genenames_had_unaccounted_for'])\n",
    "tracker_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEXT add in:\n",
    "- checking for duplicates by using `%run .ipynb` to run the notebook I made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the 'tracker_results_df' that parallels the dataframe I used to make the resulting CSV to get some idea of numbers of what rows were originally in-order matchings & balanced, plus some details of the results I made to fix things to be closer to what will easiluy make tidy data using Pandas `explode()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matching_originally</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>5651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matching_originally  count\n",
       "0                False   5651\n",
       "1                 True   1314"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo_count_df = tracker_results_df.copy().value_counts('matching_originally').reset_index()\n",
    "mo_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matching_originally</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.811342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.188658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matching_originally  proportion\n",
       "0                False    0.811342\n",
       "1                 True    0.188658"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo_count_df = tracker_results_df.copy().value_counts('matching_originally', normalize=True).reset_index()\n",
    "mo_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So not even 20% were matching the order in the two columns, `Uniprot_ACCs` & `genenames`, in the original CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_originally</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   balanced_originally  count\n",
       "0                 True   6731\n",
       "1                False    234"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_count_df = tracker_results_df.copy().value_counts('balanced_originally').reset_index()\n",
    "bal_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had this number earlier because it was what I checked initially because it was an easy check to gauge how tidy the author-provided hu.MAP 2.0 data might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>involves_semicolon</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   involves_semicolon  count\n",
       "0               False   6879\n",
       "1                True     86"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_count_df = tracker_results_df.copy().value_counts('involves_semicolon').reset_index()\n",
    "sc_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think original had semi-colon and so ones here should be well-handled. So not as big a deal now that standardized. Just printing it now since I did same for fixed hu.MAP 3.0 data for just being aware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In my 'fixed' version of the CSV data what is the amount of 'SPECIAL' cases I identified?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPECIAL_involved</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SPECIAL_involved  count\n",
       "0             False   6901\n",
       "1              True     64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_count_df = tracker_results_df.copy().value_counts('SPECIAL_involved').reset_index()\n",
    "sp_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPECIAL_involved</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.990811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.009189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SPECIAL_involved  proportion\n",
       "0             False    0.990811\n",
       "1              True    0.009189"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_count_df = tracker_results_df.copy().value_counts('SPECIAL_involved', normalize=True).reset_index()\n",
    "sp_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's quite a small fraction, below above 1%, that are 'special' cases in there now.  \n",
    "And even if these are special there is matching information in both colunns in my 'fixed' CSV to keep things explodable and utimately tidy.\n",
    "\n",
    "**Use ` humap2_complexes_20200809InOrderMatched.csv` saved above the 'accounting' I just did.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "# for development; to keep kernel active\n",
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
